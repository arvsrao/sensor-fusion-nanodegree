# Final Project - Camera



## FP.1

In function `matchBoundingBoxes` a map from previous frame box identifiers to current frame box identifiers is built. A description of my implementation:

1. With the aid of function `associateKeyPointsToBoxes` maps from keypoints to bounding boxes, in both frames, are built.
2. Each keypoint match can be interpreted as a previous frame to current frame bounding box match via the keypoint to box identifier maps built in step #1. These bounding box identifier matches are collected in a  `multimap`.
3. For each bounding box in the previous frame lookup all current frame bounding box matches in the `multimap` built in step #2. The current frame bounding box matches are then aggregated, summed, and collected in a separate map. The bounding box identifier from the current frame with the highest occurrence is the bounding box from the current frame most likely to match the given previous frame bounding box.



## FP.2

In function `computeTTCLidar` the Lidar TTC estimate is computed. The key information needed are robust measurements of the distances between the cars, in each frame. The $x$ coordinate of a lidar point is a measurement of the gap between the cars. I estimated the car distance gap by computing the median of all the $x$ coordinates of the lidar points. The median should be robust to outliers.



## FP.3

In function `clusterKptMatchesWithROI` keypoint matches judged not too far apart are set on the given bounding box. Inlier matches are those whose distance between keypoint matches is within 3 standard deviations of the mean of all keypoint match distances. Helper function  `inlierBounds` computes the the sample mean and standard deviation of the match distances. Finally, looping over the keypoint matches, inlier keypoint matches are determined by using the previously computed statistics and set on the given bounding box.



## FP.4 

A core part of the TTC camera calculation in function  `computeTTCCamera` is the robust estimation of the current/previous *match distance ratio*. Given a current keypoint match and previous keypoint match the *match distance ratio* is the ratio the distance between the keypoints of a current keypoint match and distance between the keypoints of a previous keypoint match.

Similar to the Lidar TTC computation the median match distance ratio is considered a robust estimate of the true *match distance ratio*. The distribution of match distance ratios is generated by computing the match distance ratios of all possible combinations of current and previous keypoint matches.



## FP.5 Lidar TTC Evaluation

Time-to-collision (TTC) estimates computed for **FP.5** & **FP.6** are all in the constant velocity model (CVM). To make quantitative statements about the quality of these TTC estimates I compare them to the relatively more accurate constant acceleration model (CAM) based TTC estimates. In the next section I derive a formula for TTC based on the CAM.

#### TTC When Acceleration is Constant

Measurements are taken at discrete time points $t_i$ corresponding to the $i$th Lidar/camera image. The situation at $t_i$: The ego car immediately follows another car at a distance of $d(t_i) = d_i$ meters, and both vehicles accelerate at $a(t_i) = a_i > 0$ with velocity $v(t_i) = v_i > 0$ toward each other. Supposing these conditions remain unchanged for $t >t_i$ then the cars would collide at $t_i + TTC_i$. At which point the gap between the cars is closed,
$$
0 = d(t_i + TTC_i).
$$
$TTC_i$ is the TTC at $t_i$. From kinematics the change in distance between the vehicles after $\Delta t$ starting at $t_i$ is related to the velocity and acceleration, by
$$
d(t_i + \Delta t) = d(t_i) - v(t_i)\Delta t  - \frac{1}{2}a(t_i)(\Delta t)^2.
$$
Therefore, when the two cars collide, $TTC_i$ satisfies the kinematic relationship
$$
0 = d(t_i + TTC_i) = d_i - v_i TTC_i  - \frac{1}{2}a_i TTC_i^2. \\
$$
Solving for $TTC_i$ gives 
$$
TTC_i = \frac{-v_i + \sqrt{v_i^2 + 2a_id_i}}{a_i}.
$$
The above formula for $TTC_i$ is well defined given some reasonable assumptions.

1. The cars are accelerating toward each other, $a_i > 0$, or at least the relative decceleration is small enough so as not to overwhelm the speed the cars are traveling toward each other before they collide. In the later case the discriminant gives the decceleration lower bound,
   $$
   v_i^2 + 2a_id_i \geq 0 \Longrightarrow-\frac{v_i^2}{2d_i} \leq a_i.
   $$

2. Velocity isn't constant; the TTC formula isn't defined for $a_i =0$. In such situations the TTC formula based on the CVM should be used instead.

3. It almost goes without saying but for completeness: $d_i > 0$.



Both computed Lidar CVM & CAM TTC estimates along with distance, velocity and acceleration series are shown in the table below. For reference, a python script which generates the acceleration and CAM TTC series is listed in the [appendix](#appendix). In about half of the frames CAM TTC is not defined, because the car in front is accelerating away from the ego car just enough that the cars wouldn't collide. Though, in frames where CAM TTC is defined it is consistently lower than the corresponding CMV TTC estimate.

|                            | Frame 2 | Frame 3 | Frame 4 | Frame 5 | Frame 6 | Frame 7 | Frame 8 | Frame 9 | Frame 10 | Frame 11 | Frame 12 | Frame 13 | Frame 14 | Frame 15 | Frame 16 | Frame 17 | Frame 18 | Frame 19 |
| :------------------------: | :-----: | ------- | ------- | ------- | ------- | ------- | ------- | ------- | -------- | -------- | -------- | -------- | -------- | -------- | -------- | -------- | -------- | -------- |
|    **LIDAR TTC (CVM)**     | 12.5156 | 12.6142 | 14.091  | 16.6894 | 15.7465 | 12.7835 | 12.0795 | 13.125  | 12.9128  | 11.1746  | 12.8086  | 8.95978  | 9.96439  | 9.59863  | 8.47023  | 9.58028  | 9.61241  | 8.45094  |
|  **distance ($meters$)**   |  8.01   | 7.947   | 7.891   | 7.844   | 7.794   | 7.734   | 7.67    | 7.612   | 7.554    | 7.487    | 7.429    | 7.347    | 7.274    | 7.199    | 7.115    | 7.041    | 6.969    | 6.887    |
|    **velocity ($m/s$)**    |  0.640  | 0.630   | 0.560   | 0.470   | 0.500   | 0.600   | 0.640   | 0.580   | 0.580    | 0.670    | 0.580    | 0.820    | 0.730    | 0.750    | 0.840    | 0.740    | 0.720    | 0.820    |
| **acceleration ($m/s^2$)** |   --    | -0.100  | -0.700  | -0.900  | 0.300   | 1.000   | 0.400   | -0.600  | 0.0      | 0.900    | -0.900   | 2.4      | -0.900   | 0.200    | 0.900    | -1.000   | -0.200   | 1.000    |
|    **LIDAR TTC (CAM)**     |   N/A   | N/A     | N/A     | N/A     | 5.732   | 3.378   | 4.796   | N/A     | N/A      | 3.402    | N/A      | 2.156    | N/A      | 5.526    | 3.151    | N/A      | N/A      | 2.981    |

CVM TTC significantly underestimates when compared to CAM TTC in frames where the car in front is  accelerating at a high rate toward the ego car. For example:

* *Frame 18*. The CVM TTC is more than 2.5 times the corresponding computed CAM TTC.
* *Frame 12*. The CVM TTC is more than 3.5 times the corresponding computed CAM TTC.
* *Frame 6*.   The CVM TTC is more than 3.8 times the corresponding computed CAM TTC.



## FP.6 Camera TTC Evaluation

Below is a table of CVM TTC results per frame for all possible detector/descriptor combinations. 

| Detector  | Descriptor | Frame 2 | Frame 3 | Frame 4 | Frame 5 | Frame 6 | Frame 7 | Frame 8 | Frame 9 | Frame 10 | Frame 11 | Frame 12 | Frame 13 | Frame 14 | Frame 15 | Frame 16 | Frame 17 | Frame 18 | Frame 19 |
| --------- | ---------- | :------: | :------: | :------: | :------: | :------: | :------: | :------: | :------: | :------: | :------: | :------: | :------: | :------: | :------: | :------: | :------: | :------: | :------: |
| SIFT | SIFT | 14.7405 | 15.2481 | 14.4058 | 17.7374 | 14.7413 | 14.1254 | 18.9728 | 20.4421 | 14.2554 | 18.4982 | 60.2752 | 23.9479 | 31.1241 | 30.0777 | 29.5291 | 21.1372 | 29.4262 | 20.011 |
| AKAZE | AKAZE | 19.3598 | 16.6732 | 16.3946 | 17.4944 | 15.8134 | 15.0983 | 13.1083 | 12.0352 | 12.0019 | 12.7056 | 12.8782 | 14.9701 | 13.6159 | 15.2994 | 15.5551 | 15.0461 | 15.3115 | 15.7044 |
| SHITOMASI | BRISK | 12.6897 | 14.3392 | 8.93147 | 8.10123 | 10.2075 | 8.46906 | 11.1281 | 12.6889 | 15.8872 | 12.4183 | 14.2186 | 14.872 | 19.0365 | 14.4159 | 15.5311 | 11.1392 | 16.8848 | 13.3367 |
| HARRIS | BRISK | 15.4575 | 11.0937 | 16.0231 | 15.9098 | 15.6849 | 16.9806 | 18.5282 | 17.1923 | 12.8681 | 14.3994 | 11.4526 | 18.6494 | 14.5804 | 18.7221 | 16.2317 | 16.5536 | 8.66843 | 26.6845 |
| <mark>FAST</mark> | <mark>BRISK</mark> | 13.9425 | 13.2928 | 13.4629 | 9.76266 | 9.70029 | 10.2372 | 10.2246 | 9.95748 | 6.9507 | 7.94458 | 9.69605 | 12.6532 | 10.0468 | 11.8872 | 11.84 | 11.3968 | 11.414 | 10.6524 |
| BRISK | BRISK | 16.3479 | 20.321 | 14.9676 | 15.1505 | 15.3407 | 13.2439 | 11.3369 | 11.386 | 10.5042 | 13.8248 | 13.8499 | 14.968 | 12.714 | 13.1987 | 16.8008 | 16.851 | 14.9111 | 17.4903 |
| ORB | BRISK | 36.353 | 31.1156 | 40.4474 | 23.059 | 77.039 | 32.1794 | 274.136 | 57.6915 | 132.011 | 145.064 | 41.0883 | 21.1764 | 99.1052 | 69.6904 | 99.9423 | inf | 65.5688 | 121.305 |
| SHITOMASI | BRIEF | 15.494 | 17.3436 | 14.323 | 14.4477 | 14.702 | 14.09 | 17.9349 | 18.3665 | 16.1532 | 20.1432 | 19.9786 | 27.5593 | 27.0131 | 34.3023 | 35.5981 | 28.6583 | 30.7982 | 25.3829 |
| HARRIS | BRIEF | 18.8051 | 15.2462 | 18.3338 | 23.8514 | 19.9363 | 20.7022 | 21.4574 | 18.2781 | 17.3958 | 18.8172 | 20.3807 | 17.9713 | 21.9755 | 21.952 | 23.022 | 25.5628 | 20.2789 | 110.111 |
| FAST | BRIEF | 20.0144 | 19.3049 | 18.2329 | 15.7546 | 16.129 | 16.3116 | 15.6647 | 16.3584 | 15.5883 | 15.5883 | 15.8718 | 19.6431 | 18.8613 | 20.0802 | 19.4064 | 18.1532 | 18.4007 | 20.1843 |
| BRISK | BRIEF | 19.6723 | 19.5012 | 18.5812 | 16.3493 | 17.0567 | 15.1997 | 15.0124 | 15.2618 | 14.2729 | 15.9055 | 15.0263 | 16.1697 | 15.4888 | 15.7787 | 17.2591 | 19.3711 | 18.7307 | 20.9674 |
| ORB | BRIEF | 28.8778 | 28.2788 | 30.4452 | 28.0893 | 76.3276 | 50.2846 | 68.5289 | 1210.93 | 52.834 | 236.724 | 43.8159 | 30.8714 | 30.5106 | 28.1764 | 39.9311 | 38.51 | 61.0738 | 74.6644 |
| SHITOMASI | ORB | 15.051 | 14.3331 | 11.4708 | 14.2039 | 12.1594 | 15.2813 | 12.5654 | 12.9921 | 10.8879 | 15.1303 | 17.3811 | 17.4431 | 23.9618 | 22.5198 | 20.2947 | 14.042 | 13.8942 | 19.1895 |
| <mark>HARRIS</mark> | <mark>ORB</mark> | 7.84727 | 6.25208 | 8.88084 | 17.0268 | 18.4969 | 18.5274 | 13.1077 | 11.8668 | 5.07065 | 11.9619 | 7.65097 | 12.5896 | 8.34815 | 12.4783 | 12.3021 | 11.9407 | 4.65318 | 14.7013 |
| FAST | ORB | 18.9625 | 16.4274 | 16.6095 | 14.7479 | 16.2642 | 15.4055 | 15.4182 | 14.7785 | 15.1916 | 16.3462 | 16.9246 | 18.3683 | 17.3618 | 18.5732 | 20.7734 | 19.006 | 17.9569 | 20.5559 |
| BRISK | ORB | 16.1647 | 18.1798 | 15.4833 | 13.4438 | 15.3072 | 11.7462 | 13.5469 | 11.4164 | 10.9917 | 13.1373 | 12.2645 | 15.0007 | 11.1982 | 14.1691 | 15.6596 | 16.8864 | 15.8187 | 17.5766 |
| ORB | ORB | 25.083 | 21.1027 | 53.5052 | 82.0826 | 365.356 | 65.9501 | 31.4278 | 123.37 | 30.6829 | 47.2151 | 49.7533 | 27.721 | 58.3156 | 36.7971 | 37.5662 | 40.3458 | 97.6609 | 85.7114 |
| <mark>SHITOMASI</mark> | <mark>FREAK</mark> | 13.2268 | 12.653 | 7.55326 | 8.23473 | 10.031 | 7.57453 | 11.7986 | 9.12413 | 8.81053 | 10.9063 | 9.65126 | 9.14327 | 17.2502 | 11.9393 | 16.0782 | 11.8818 | 14.9487 | 11.1092 |
| HARRIS | FREAK | 14.7069 | 10.8266 | 14.0473 | 17.0876 | 17.6889 | 17.7521 | 14.9956 | 15.3889 | 11.0998 | 13.2743 | 9.54391 | 18.492 | 11.1894 | 14.3108 | 19.9916 | 14.9421 | 10.2236 | 30.001 |
| <mark>FAST</mark> | <mark>FREAK</mark> | 14.3836 | 13.846 | 12.8054 | 11.3465 | 11.526 | 9.90328 | 11.9316 | 9.98022 | 8.53141 | 9.47292 | 11.1442 | 12.8575 | 11.7891 | 12.3166 | 12.2508 | 12.2131 | 12.9715 | 14.2303 |
| BRISK | FREAK | 18.2228 | 18.9345 | 14.1975 | 14.6406 | 14.7528 | 12.8543 | 12.8777 | 12.4832 | 11.7423 | 13.1632 | 14.0711 | 12.4779 | 12.3321 | 12.0043 | 14.3199 | 16.592 | 15.3574 | 21.1011 |
| ORB | FREAK | 15.541 | 14.3713 | 11.6149 | 16.3986 | 19.2742 | 87.7275 | inf | inf | -40.7836 | -81.7471 | inf | 167.99 | -220.426 | inf | inf | inf | 129.893 | -68.8638 |



#### Detector - Descriptor Pairs Which Perform Poorly

<figure>
<div align="center">
	<img src = "/Users/arvind/Library/Application Support/typora-user-images/image-20220519164630457.png">
</div>
<figcaption> 
Figure #1.  CVM TTC series for ORB - BRISK, ORB - ORB, ORB - BRIEF, and ORB - FREAK.
</figcaption>
</figure>


Among all pairs *ORB - BRISK*, *ORB - ORB*, *ORB - FREAK*, and *ORB -BRIEF* produce especially very poor TTC estimates. In Figures #1 one sees clearly that many of the TTC results are in the hundreds of seconds, and in the case of *ORB - FREAK* are negative and infinite/not-defined. The common factor is the detector, ORB. By contrast, detector - descriptor pairs where ORB is the descriptor and not the detector (SHITOMASI - ORB, HARRIS - ORB, FAST - ORB, and BRISK - ORB) all produce TTC results (Figure #2 below) within a 7 - 24 second range. Considering the relative distances and velocities of the cars, these are more plausible TTC values.

<figure>
<div align="center">
	<img src = "/Users/arvind/Library/Application Support/typora-user-images/image-20220519164904941.png">
</div>
<figcaption> 
Figure #2. CVM TTC series for BRISK - ORB, SHITOMASI - ORB, HARRIS - ORB, and FAST - ORB.
</figcaption>
</figure>

A conclusion one could drawn is ORB keypoints are difficult to accurately match. I suspect it has to do with their size. ORB tends to produce large keypoints, because detection is done on multiple resolutions of the input image. Furthermore, ORB keypoints are large relative to the size of the car being followed, leading to large overlaps which could mean their binary descriptions are difficult to differentiate.



#### Detector - Descriptor Pairs Which Perform Well

Detector - descriptor pairs I judge to be good / reasonable are <mark>highlighted</mark> in the camera TTC table above and are graphed below in Figure #3. These pairs all exhibit the narrowest TTC ranges among all detector - descriptor pairs.



<figure>
<div align="center">
	<img src = "/Users/arvind/Library/Application Support/typora-user-images/image-20220519165347574.png">
</div>
<figcaption> 
Figure #3. CVM TTC series for HARRIS - ORB, SHITOMASI - FREAK, FAST - FREAK, and FAST - BRISK.
</figcaption>
</figure>


Of the four good detector - descriptor pairs FAST - FREAK and FAST - BRISK are the least volatile and have the smallest range of TTC values. Interestingly, both FAST - FREAK and FAST - BRISK detect considerably more keypoints and subsequently generate considerably more matches than the other two pairs, SHITOMASI - FREAK and HARRIS - ORB, see Figures #4 and #5 below. More keypoints detected and matched leads to a denser sampling of the matched distance ratio distribution in function `clusterKptMatchesWithROI`. Which in turn leads to improved outlier filtering of matches. Later in `computeTTCCamera` a larger set of matches imply a denser sampling of the distance ratio distribution, leading to a more accurate estimate of the median ratio.

<figure>
<div align="center">
	<img src = "/Users/arvind/Library/Application Support/typora-user-images/image-20220520112415052.png">
</div>
<figcaption> 
Figure #4. Number of keypoints detected by pairs FAST - FREAK, FAST - BRISK, SHITOMASI - FREAK and HARRIS - ORB.
</figcaption>
</figure>



<figure>
<div align="center">
	<img src = "/Users/arvind/Library/Application Support/typora-user-images/image-20220520112513359.png">
</div>
<figcaption> 
Figure #5. Number of keypoint matches by pairs FAST - FREAK, FAST - BRISK, SHITOMASI - FREAK and HARRIS - ORB.
</figcaption>
</figure>



<a name="appendix"></a>


## Appendix

Code for generating the acceleration series and CAM TTC series is listed below.

```python
from math import sqrt

# a symbol that represents N/A
NotApplicableSymbol = -1e6

# precomputed distances and velocities per frame
d = [8.01 , 7.947, 7.891, 7.844, 7.794, 7.734, 7.67 , 7.612, 7.554, 7.487, 7.429, 7.347, 7.274, 7.199, 7.115, 7.041, 6.969, 6.887]
v = [0.640, 0.630, 0.560, 0.470, 0.500, 0.600, 0.640, 0.580, 0.580, 0.670, 0.580, 0.820, 0.730, 0.750, 0.840, 0.740, 0.720, 0.820]

a = [NotApplicableSymbol]
ttcs = [NotApplicableSymbol]
deltaT = 0.1

# compute accelation for each frame
for idx in range(0, len(v)-1):
	a.append((v[idx+1] - v[idx]) / deltaT)

# compute CAM TTC
def ttc(di,vi,ai):
  discriminant = vi*vi + 2 * ai * di
	if (discriminant >=0 and ai != 0.0):
		return (-vi + sqrt(discriminant))/ai
	else:
		return NotApplicableSymbol # mark as N/A

# generate CAM TTC series
for idx in range(0, len(d)):
	t = ttc(d[idx], v[idx], a[idx])
	print(idx+1, t)
```

